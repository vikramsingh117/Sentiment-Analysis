# -*- coding: utf-8 -*-
"""Project 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1krFHBBgCQAwtYHTq-F1ox2P8CusErnkz

# Stock market dynamics - Sentiment Analysis

Analyzing the News Headlines dataset and building classification models to predict if the sentiment of a given input sentence is positive or negative. Based on this we predict if the stock will go up or down

#Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.stem.porter import PorterStemmer
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from wordcloud import WordCloud
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
import pickle
import re

"""#EDA"""

#Load the data
dataset = pd.read_csv(r"Data.csv", encoding = 'latin-1')

dataset.head()

dataset = dataset.rename(columns={'neutral':'Label','According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .':'News'})

dataset.head()

# @title Label

from matplotlib import pyplot as plt
import seaborn as sns
dataset.groupby('Label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

#Analyzing Label column
print(f"Label value count: \n{dataset['rating'].value_counts()}")

#Check for null values
dataset.isnull().sum()

# Convertng headlines to lower case
for index in range(len(dataset)): # Use range() to generate a sequence of numbers
    dataset.loc[index, 'News'] = dataset.loc[index, 'News'].lower() # Use .loc to access and modify cell value
dataset.head()

cv = CountVectorizer(stop_words='english')
words = cv.fit_transform(dataset.News)

# Finding unique words in each news category
neg_news = " ".join([news for news in dataset[dataset['Label'] == 'negative']['News']])
neg_news = neg_news.lower().split()

pos_news = " ".join([news for news in dataset[dataset['Label'] == 'positive']['News']])
pos_news = pos_news.lower().split()

#Finding unique words in each label
unique_negative = [x for x in neg_news if x not in pos_news]
unique_negative = " ".join(unique_negative)

unique_positive = [x for x in pos_news if x not in neg_news]
unique_positive = " ".join(unique_positive)

wc = WordCloud(background_color='white', max_words=50)

# Generate and plot wordcloud
plt.figure(figsize=(10,10))
plt.imshow(wc.generate(unique_negative))
plt.title('Wordcloud for negative news', fontsize=10)
plt.axis('off')
plt.show()

wc = WordCloud(background_color='white', max_words=50)

# Generate and plot wordcloud
plt.figure(figsize=(10,10))
plt.imshow(wc.generate(unique_positive))
plt.title('Wordcloud for positive news', fontsize=10)
plt.axis('off')
plt.show()

"""# Preprocessing and Modelling

"""

corpus = []
stemmer = PorterStemmer()
for i in range(0, dataset.shape[0]):
  # Access each headline using i as index
  news = re.sub('[^a-zA-Z]', ' ', dataset.iloc[i]['News'])
  news = news.lower().split()
  news = [stemmer.stem(word) for word in news if not word in STOPWORDS]
  news = ' '.join(news)
  corpus.append(news)

dataset['News'][0]

corpus[0]

# Initialize wordcloud object
wc = WordCloud(background_color='white', max_words=50)

news = " ".join(corpus)
# Generate and plot wordcloud
plt.figure(figsize=(10,10))
plt.imshow(wc.generate(news))
plt.title('Headlines without stopwords', fontsize=10)
plt.axis('off')
plt.show()

cv = CountVectorizer(max_features = 2500)

#Storing independent and dependent variables in X and y
X = cv.fit_transform(corpus).toarray()
y = dataset['Label'].values

print(f"X shape: {X.shape}")
print(f"y shape: {y.shape}")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 15)

print(f"X train: {X_train.shape}")
print(f"y train: {y_train.shape}")
print(f"X test: {X_test.shape}")
print(f"y test: {y_test.shape}")

#Fitting scaled X_train and y_train on Random Forest Classifier
model_rf = RandomForestClassifier()
model_rf.fit(X_train, y_train)

#Decision tree classifier
model_dt = DecisionTreeClassifier()
model_dt.fit(X_train, y_train)

"""Random forest Validation"""

#Accuracy of the model on training and testing data

print("Training Accuracy :", model_rf.score(X_train, y_train))
print("Testing Accuracy :", model_rf.score(X_test, y_test))

#Predicting on the test set
y_preds = model_rf.predict(X_test)

#Confusion Matrix
cm = confusion_matrix(y_test, y_preds)

cm_display = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model_rf.classes_)
cm_display.plot()
plt.show()

accuracies = cross_val_score(estimator = model_rf, X = X_train, y = y_train, cv = 10)

print("Accuracy :", accuracies.mean())
print("Standard Variance :", accuracies.std())

"""Decision Tree Validation"""

print("Training Accuracy :", model_dt.score(X_train, y_train))
print("Testing Accuracy :", model_dt.score(X_test, y_test))

y_preds = model_dt.predict(X_test)

#Confusion Matrix
cm = confusion_matrix(y_test, y_preds)
print(cm)

cm_display = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model_dt.classes_)
cm_display.plot()
plt.show()

"""Hyperparameter tuning"""

params = {
    'bootstrap': [True],
    'max_depth': [80, 100],
    'min_samples_split': [8, 12],
    'n_estimators': [100, 300]
}

cv_object = StratifiedKFold(n_splits = 2)

grid_search = GridSearchCV(estimator = model_rf, param_grid = params, cv = cv_object, verbose = 0, return_train_score = True)
grid_search.fit(X_train, y_train.ravel())

#Getting the best parameters from the grid search
print("Best Parameter Combination : {}".format(grid_search.best_params_))

print("Cross validation mean accuracy on train set : {}".format(grid_search.cv_results_['mean_train_score'].mean()*100))
print("Cross validation mean accuracy on test set : {}".format(grid_search.cv_results_['mean_test_score'].mean()*100))
print("Accuracy score for test set :", accuracy_score(y_test, y_preds))

